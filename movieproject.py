# -*- coding: utf-8 -*-
"""Movieproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14v9_wPhRmboCAz4Gdy1XNJ0H_bJIp7V4
"""

import pandas as pd
import numpy as np
import ast

from google.colab import drive
drive.mount('/content/drive')

movies=pd.read_csv('/content/drive/MyDrive/movies.csv')
credits=pd.read_csv('/content/drive/MyDrive/credits.csv')

movies.head(1)

credits.head(1)

movies=movies.merge(credits,on='title')

movies.head()

#columns we are keeping: genre,id,key_words,title,overview,cast,crew
movies=movies[['movie_id','title','overview','genres','keywords','cast','crew']]

movies.head()

#checking for missing values
movies.isnull().sum()

movies.dropna(inplace=True)
movies.isnull().sum()

movies.iloc[0].genres

#[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]
#we want to covert it n a python list, that looks like this: ['Action','Adventure','Fantasy','Science Fiction']

def convert(obj):
  L=[]
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

movies['genres']=movies['genres'].apply(convert)
movies.head()

movies['keywords']=movies['keywords'].apply(convert)
movies.head()

#in case of cask we better take the first 3 actors from the string because they are most important and  then converts them into  a clean list
def convert3(obj):
  L=[]
  counter=0
  for i in ast.literal_eval(obj):
    if counter !=3:
      L.append(i['name'])
      counter+=1
    else:
      break
  return L

movies['cast']=movies['cast'].apply(convert3)
movies.head()

movies['crew'][0]

def fetch_director(obj):
  L=[]
  for i in ast.literal_eval(obj):
    if i['job']=='Director':
      L.append(i['name'])
      break
  return L

movies['crew']=movies['crew'].apply(fetch_director)
movies.head()

movies['overview'][0]

movies['overview']=movies['overview'].apply(lambda x:x.split())# Split the overview into a list of words

movies.head()

#now we need to remove the spaces between the words like we need Sam Worthington as SamWorthington because of getting recomendation based on them sam we want not any other sam in the list
movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","")for i in x])
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","")for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","")for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","")for i in x])
movies.head()

movies['tags']=movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']
movies.head()

new_df=movies[['movie_id','title','tags']]
new_df

new_df['tags']=new_df['tags'].apply(lambda x:" ".join(x)) #converting it back into a single string for each movie
new_df['tags']=new_df['tags'].apply(lambda x:x.lower())

new_df.head()

#vectorization process
from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=2000,stop_words='english')
vectors=cv.fit_transform(new_df['tags']).toarray()
vectors

from os import posix_spawn
#the problem here is that count vectorizor may using words like action , actions ,actioned asdifferent words but actually they are same accorfing to their context
# so we have to do something to get these words same and not use repeatidly as different in suggesting movies
import nltk
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()

def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)

# short application of our stem function to see how it works(run only to understand the working of stem function)
# print(ps.stem('action'))
# print(ps.stem('actions'))
# print(ps.stem('actioned'))

new_df['tags']=new_df['tags'].apply(stem)
#now were applying the countvectorizer again on our stemmed tags column in the dataset(run the vectorizor code again)

#now we need to calculate the similarity between the movies using their cosine distance 'theta' in the 5000D plane
from sklearn.metrics.pairwise import cosine_similarity
similarity=cosine_similarity(vectors)

#main rocomender function that will recomend(return) 5 movies similar to the given movie
def recomend(movie):
    movie_index = new_df[new_df['title'] == movie].index[0]   # Find index
    distance = similarity[movie_index]                         # Get similarity scores
    movies_list = sorted(list(enumerate(distance)), reverse=True, key=lambda x: x[1])[1:6]
    for i in movies_list:
        print(new_df.iloc[i[0]].title)

recomend('Avatar')

import pickle
pickle.dump(new_df,open('movies.pkl','wb'))

pickle.dump(new_df.to_dict(),open('movie_dict.pkl','wb'))

pickle.dump(similarity,open('similarity.pkl','wb'))

